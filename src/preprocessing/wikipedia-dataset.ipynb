{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "3606dd4a",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/Users/memento/Documents/Studium/Master/IR/IR_Praktikum/.env/lib/python3.13/site-packages/tqdm/auto.py:21: TqdmWarning: IProgress not found. Please update jupyter and ipywidgets. See https://ipywidgets.readthedocs.io/en/stable/user_install.html\n",
      "  from .autonotebook import tqdm as notebook_tqdm\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "WARNING: faiss must be imported for indexing\n"
     ]
    }
   ],
   "source": [
    "import os \n",
    "import sys \n",
    "from colbert.infra import Run, RunConfig, ColBERTConfig\n",
    "from colbert.data import Queries, Collection\n",
    "from colbert import Indexer, Searcher\n",
    "from datasets import load_dataset\n",
    "\n",
    "ds = load_dataset(\"wikimedia/wikipedia\", \"20231101.en\")\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "039f3855",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "DatasetDict({\n",
       "    train: Dataset({\n",
       "        features: ['id', 'url', 'title', 'text'],\n",
       "        num_rows: 6407814\n",
       "    })\n",
       "})"
      ]
     },
     "execution_count": 2,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "ds"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "e052dfd2",
   "metadata": {},
   "outputs": [
    {
     "ename": "KeyboardInterrupt",
     "evalue": "",
     "output_type": "error",
     "traceback": [
      "\u001b[31m---------------------------------------------------------------------------\u001b[39m",
      "\u001b[31mKeyboardInterrupt\u001b[39m                         Traceback (most recent call last)",
      "\u001b[36mCell\u001b[39m\u001b[36m \u001b[39m\u001b[32mIn[3]\u001b[39m\u001b[32m, line 1\u001b[39m\n\u001b[32m----> \u001b[39m\u001b[32m1\u001b[39m \u001b[43mds\u001b[49m\u001b[43m[\u001b[49m\u001b[33;43m'\u001b[39;49m\u001b[33;43mtrain\u001b[39;49m\u001b[33;43m'\u001b[39;49m\u001b[43m]\u001b[49m\u001b[43m[\u001b[49m\u001b[33;43m'\u001b[39;49m\u001b[33;43mtext\u001b[39;49m\u001b[33;43m'\u001b[39;49m\u001b[43m]\u001b[49m[:\u001b[32m3\u001b[39m]\n",
      "\u001b[36mFile \u001b[39m\u001b[32m~/Documents/Studium/Master/IR/IR_Praktikum/.env/lib/python3.13/site-packages/datasets/arrow_dataset.py:2777\u001b[39m, in \u001b[36mDataset.__getitem__\u001b[39m\u001b[34m(self, key)\u001b[39m\n\u001b[32m   2775\u001b[39m \u001b[38;5;28;01mdef\u001b[39;00m\u001b[38;5;250m \u001b[39m\u001b[34m__getitem__\u001b[39m(\u001b[38;5;28mself\u001b[39m, key):  \u001b[38;5;66;03m# noqa: F811\u001b[39;00m\n\u001b[32m   2776\u001b[39m \u001b[38;5;250m    \u001b[39m\u001b[33;03m\"\"\"Can be used to index columns (by string names) or rows (by integer index or iterable of indices or bools).\"\"\"\u001b[39;00m\n\u001b[32m-> \u001b[39m\u001b[32m2777\u001b[39m     \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[38;5;28;43mself\u001b[39;49m\u001b[43m.\u001b[49m\u001b[43m_getitem\u001b[49m\u001b[43m(\u001b[49m\u001b[43mkey\u001b[49m\u001b[43m)\u001b[49m\n",
      "\u001b[36mFile \u001b[39m\u001b[32m~/Documents/Studium/Master/IR/IR_Praktikum/.env/lib/python3.13/site-packages/datasets/arrow_dataset.py:2762\u001b[39m, in \u001b[36mDataset._getitem\u001b[39m\u001b[34m(self, key, **kwargs)\u001b[39m\n\u001b[32m   2760\u001b[39m formatter = get_formatter(format_type, features=\u001b[38;5;28mself\u001b[39m._info.features, **format_kwargs)\n\u001b[32m   2761\u001b[39m pa_subtable = query_table(\u001b[38;5;28mself\u001b[39m._data, key, indices=\u001b[38;5;28mself\u001b[39m._indices)\n\u001b[32m-> \u001b[39m\u001b[32m2762\u001b[39m formatted_output = \u001b[43mformat_table\u001b[49m\u001b[43m(\u001b[49m\n\u001b[32m   2763\u001b[39m \u001b[43m    \u001b[49m\u001b[43mpa_subtable\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mkey\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mformatter\u001b[49m\u001b[43m=\u001b[49m\u001b[43mformatter\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mformat_columns\u001b[49m\u001b[43m=\u001b[49m\u001b[43mformat_columns\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43moutput_all_columns\u001b[49m\u001b[43m=\u001b[49m\u001b[43moutput_all_columns\u001b[49m\n\u001b[32m   2764\u001b[39m \u001b[43m\u001b[49m\u001b[43m)\u001b[49m\n\u001b[32m   2765\u001b[39m \u001b[38;5;28;01mreturn\u001b[39;00m formatted_output\n",
      "\u001b[36mFile \u001b[39m\u001b[32m~/Documents/Studium/Master/IR/IR_Praktikum/.env/lib/python3.13/site-packages/datasets/formatting/formatting.py:653\u001b[39m, in \u001b[36mformat_table\u001b[39m\u001b[34m(table, key, formatter, format_columns, output_all_columns)\u001b[39m\n\u001b[32m    651\u001b[39m python_formatter = PythonFormatter(features=formatter.features)\n\u001b[32m    652\u001b[39m \u001b[38;5;28;01mif\u001b[39;00m format_columns \u001b[38;5;129;01mis\u001b[39;00m \u001b[38;5;28;01mNone\u001b[39;00m:\n\u001b[32m--> \u001b[39m\u001b[32m653\u001b[39m     \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[43mformatter\u001b[49m\u001b[43m(\u001b[49m\u001b[43mpa_table\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mquery_type\u001b[49m\u001b[43m=\u001b[49m\u001b[43mquery_type\u001b[49m\u001b[43m)\u001b[49m\n\u001b[32m    654\u001b[39m \u001b[38;5;28;01melif\u001b[39;00m query_type == \u001b[33m\"\u001b[39m\u001b[33mcolumn\u001b[39m\u001b[33m\"\u001b[39m:\n\u001b[32m    655\u001b[39m     \u001b[38;5;28;01mif\u001b[39;00m key \u001b[38;5;129;01min\u001b[39;00m format_columns:\n",
      "\u001b[36mFile \u001b[39m\u001b[32m~/Documents/Studium/Master/IR/IR_Praktikum/.env/lib/python3.13/site-packages/datasets/formatting/formatting.py:408\u001b[39m, in \u001b[36mFormatter.__call__\u001b[39m\u001b[34m(self, pa_table, query_type)\u001b[39m\n\u001b[32m    406\u001b[39m     \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[38;5;28mself\u001b[39m.format_row(pa_table)\n\u001b[32m    407\u001b[39m \u001b[38;5;28;01melif\u001b[39;00m query_type == \u001b[33m\"\u001b[39m\u001b[33mcolumn\u001b[39m\u001b[33m\"\u001b[39m:\n\u001b[32m--> \u001b[39m\u001b[32m408\u001b[39m     \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[38;5;28;43mself\u001b[39;49m\u001b[43m.\u001b[49m\u001b[43mformat_column\u001b[49m\u001b[43m(\u001b[49m\u001b[43mpa_table\u001b[49m\u001b[43m)\u001b[49m\n\u001b[32m    409\u001b[39m \u001b[38;5;28;01melif\u001b[39;00m query_type == \u001b[33m\"\u001b[39m\u001b[33mbatch\u001b[39m\u001b[33m\"\u001b[39m:\n\u001b[32m    410\u001b[39m     \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[38;5;28mself\u001b[39m.format_batch(pa_table)\n",
      "\u001b[36mFile \u001b[39m\u001b[32m~/Documents/Studium/Master/IR/IR_Praktikum/.env/lib/python3.13/site-packages/datasets/formatting/formatting.py:459\u001b[39m, in \u001b[36mPythonFormatter.format_column\u001b[39m\u001b[34m(self, pa_table)\u001b[39m\n\u001b[32m    458\u001b[39m \u001b[38;5;28;01mdef\u001b[39;00m\u001b[38;5;250m \u001b[39m\u001b[34mformat_column\u001b[39m(\u001b[38;5;28mself\u001b[39m, pa_table: pa.Table) -> \u001b[38;5;28mlist\u001b[39m:\n\u001b[32m--> \u001b[39m\u001b[32m459\u001b[39m     column = \u001b[38;5;28;43mself\u001b[39;49m\u001b[43m.\u001b[49m\u001b[43mpython_arrow_extractor\u001b[49m\u001b[43m(\u001b[49m\u001b[43m)\u001b[49m\u001b[43m.\u001b[49m\u001b[43mextract_column\u001b[49m\u001b[43m(\u001b[49m\u001b[43mpa_table\u001b[49m\u001b[43m)\u001b[49m\n\u001b[32m    460\u001b[39m     column = \u001b[38;5;28mself\u001b[39m.python_features_decoder.decode_column(column, pa_table.column_names[\u001b[32m0\u001b[39m])\n\u001b[32m    461\u001b[39m     \u001b[38;5;28;01mreturn\u001b[39;00m column\n",
      "\u001b[36mFile \u001b[39m\u001b[32m~/Documents/Studium/Master/IR/IR_Praktikum/.env/lib/python3.13/site-packages/datasets/formatting/formatting.py:146\u001b[39m, in \u001b[36mPythonArrowExtractor.extract_column\u001b[39m\u001b[34m(self, pa_table)\u001b[39m\n\u001b[32m    145\u001b[39m \u001b[38;5;28;01mdef\u001b[39;00m\u001b[38;5;250m \u001b[39m\u001b[34mextract_column\u001b[39m(\u001b[38;5;28mself\u001b[39m, pa_table: pa.Table) -> \u001b[38;5;28mlist\u001b[39m:\n\u001b[32m--> \u001b[39m\u001b[32m146\u001b[39m     \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[43mpa_table\u001b[49m\u001b[43m.\u001b[49m\u001b[43mcolumn\u001b[49m\u001b[43m(\u001b[49m\u001b[32;43m0\u001b[39;49m\u001b[43m)\u001b[49m\u001b[43m.\u001b[49m\u001b[43mto_pylist\u001b[49m\u001b[43m(\u001b[49m\u001b[43m)\u001b[49m\n",
      "\u001b[31mKeyboardInterrupt\u001b[39m: "
     ]
    }
   ],
   "source": [
    "ds['train']['text'][:3]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "f310865e",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "11it [00:00, 2381.41it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Anarchism\n",
      "Albedo\n",
      "A\n",
      "Alabama\n",
      "Achilles\n",
      "Abraham Lincoln\n",
      "Aristotle\n",
      "An American in Paris\n",
      "Academy Award for Best Production Design\n",
      "Academy Awards\n",
      "Actrius\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n"
     ]
    }
   ],
   "source": [
    "from tqdm import tqdm\n",
    "for i, entry in tqdm(enumerate(iter(ds['train']))):\n",
    "    if i>10:\n",
    "        break\n",
    "    print(entry['title'])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "e3184c99",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "6407814it [03:16, 32624.71it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Regular documents: 6352465\n",
      "Disambiguation documents: 55349\n"
     ]
    }
   ],
   "source": [
    "\n",
    "'''\n",
    "Datasets I want to have in the dataset: \n",
    "- d_id, title(label), text(erster absatz bis zum ersten \\n\\n)\n",
    "- disambiguation dataset\n",
    "'''\n",
    "\n",
    "import pandas as pd\n",
    "from tqdm import tqdm\n",
    "import re\n",
    "import os\n",
    "\n",
    "def clean_label(label):\n",
    "    pattern = r'\\([^)]*\\)'\n",
    "    # Replace all matches with an empty string\n",
    "    result = re.sub(pattern, '', label)\n",
    "    return result.strip()  # Added strip() to remove any trailing spaces\n",
    "\n",
    "def clean_text(text):\n",
    "    if '\\n\\n' in text:\n",
    "        text_cut = text.split('\\n\\n')[0]\n",
    "    else:\n",
    "        text_cut = text\n",
    "    return text_cut\n",
    "\n",
    "def is_disambiguation(label):\n",
    "    # Check if the label contains \"(disambiguation)\"\n",
    "    return \"(disambiguation)\" in label\n",
    "\n",
    "def format_doc_id(index):\n",
    "    # Format with 7 digits (since there are 6,352,465 docs total)\n",
    "    return f\"d_{index:07d}\"\n",
    "\n",
    "# Initialize empty DataFrames\n",
    "doc_df = pd.DataFrame(columns=['d_id', 'label', 'text'])\n",
    "disambiguation_df = pd.DataFrame(columns=['d_id', 'label', 'text'])\n",
    "\n",
    "# Lists to store rows for each DataFrame (more efficient than append)\n",
    "doc_rows = []\n",
    "disambiguation_rows = []\n",
    "\n",
    "for i, entry in tqdm(enumerate(iter(ds['train']))):\n",
    "    # Check if it's a disambiguation page before cleaning\n",
    "    doc_id = format_doc_id(i + 1)\n",
    "    if is_disambiguation(entry['title']):\n",
    "        disambiguation_rows.append({'d_id': doc_id, 'label': entry['title'], 'text': entry['text']})\n",
    "    else:\n",
    "        # For regular documents\n",
    "        cleaned_label = clean_label(entry['title'])\n",
    "        cleaned_text = clean_text(entry['text'])\n",
    "        doc_rows.append({'d_id': doc_id, 'label': cleaned_label, 'text': cleaned_text})\n",
    "\n",
    "    # Create DataFrames from the collected rows (much more efficient)\n",
    "    \n",
    "doc_df = pd.DataFrame(doc_rows)\n",
    "disambiguation_df = pd.DataFrame(disambiguation_rows)\n",
    "\n",
    "# Print some stats to verify\n",
    "print(f\"Regular documents: {len(doc_df)}\")\n",
    "print(f\"Disambiguation documents: {len(disambiguation_df)}\")\n",
    "pwd = os.getcwd()\n",
    "datapath = os.path.join(pwd, '../../data/wikipedia')\n",
    "os.makedirs(datapath, exist_ok=True)\n",
    "doc_df.to_pickle(path=os.path.join(datapath, 'wikipedia-text-data-no-disambiguation.pkl.gzip'), compression='gzip')\n",
    "disambiguation_df.to_pickle(path=os.path.join(datapath, 'wikipedia-disambiguation-data.pkl.gzip'), compression='gzip')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "5da0d695",
   "metadata": {},
   "outputs": [],
   "source": [
    "i = 0\n",
    "while(True):\n",
    "    if (i*500000)-1 > 6352465:\n",
    "        break\n",
    "    wd = os.getcwd()\n",
    "    datapath = os.path.join(pwd, '../../data/wikipedia/split-data-no-disambiguation')\n",
    "    os.makedirs(datapath, exist_ok=True)    \n",
    "    \n",
    "    doc_df[i*500000:((i+1)*500000)-1].to_pickle(path=os.path.join(datapath, f'wikipedia-text-data-no-disambiguation_{i}.pkl.gzip'), compression='gzip')\n",
    "    i=i+1"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "ca6026c1",
   "metadata": {},
   "source": [
    "ds['train']['text'][:3]"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "9ba5fd09",
   "metadata": {},
   "source": [
    "# Add test dataset with just articals containing\n",
    "+ Jaguar\n",
    "+ Hammer\n",
    "+ Coke\n",
    "+ Pope\n",
    "+ Comic\n",
    "+ Drink\n",
    "+ Cat\n",
    "+ Dwarf\n",
    "+ Game\n",
    "+ Texas\n",
    "\n",
    "# Add Query Dataset for all disambiguations"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "a8382d56",
   "metadata": {},
   "outputs": [
    {
     "ename": "NameError",
     "evalue": "name 'disambiguation_df' is not defined",
     "output_type": "error",
     "traceback": [
      "\u001b[31m---------------------------------------------------------------------------\u001b[39m",
      "\u001b[31mNameError\u001b[39m                                 Traceback (most recent call last)",
      "\u001b[36mCell\u001b[39m\u001b[36m \u001b[39m\u001b[32mIn[1]\u001b[39m\u001b[32m, line 1\u001b[39m\n\u001b[32m----> \u001b[39m\u001b[32m1\u001b[39m \u001b[43mdisambiguation_df\u001b[49m[:\u001b[32m20\u001b[39m]\n",
      "\u001b[31mNameError\u001b[39m: name 'disambiguation_df' is not defined"
     ]
    }
   ],
   "source": [
    "disambiguation_df[:20]"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": ".env",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.13.3"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
